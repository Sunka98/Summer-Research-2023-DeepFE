{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMGwYlrrT9NNixox8bljJgg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FX5dZN9sX4en"},"outputs":[],"source":["#####################################################\n","# PLEASE RUN THIS FIRST OTHERWISE NOTHING WILL WORK #\n","#####################################################\n","\n","\n","import os\n","import shutil\n","\n","directory = \"/content/Math-4997-Summer-23\"\n","shutil.rmtree(directory)\n","!git clone https://github.com/skylarwilson/Math-4997-Summer-23\n","print(\"\\nFILE UPLOADING DONE, YOU MAY PROCEED.\")"]},{"cell_type":"code","source":["###########################################\n","# THIS IS THE MODEL OF THE NEURAL NETWORK #\n","# PLEASE RUN THIS NEXT                    #\n","#                                         #\n","# IF YOU MADE CHANGES TO THE MODEL        #\n","# PLEASE RERUN THIS CODE                  #\n","###########################################\n","\n","# Model Definition\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Model Definition\n","class CountingModel(nn.Module):\n","    def __init__(self):\n","        super(CountingModel, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n","\n","        # Pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(128 * 484, 8)  # Adjusted input size\n","        self.fc2 = nn.Linear(8, 1)\n","\n","    def forward(self, x):\n","        # Apply convolutional layers\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","\n","        # Determine the output size after pooling\n","        _, _, height, width = x.size()\n","        output_size = height * width * 128\n","\n","        # Flatten the tensor\n","        x = x.view(-1, output_size)\n","\n","        # Apply fully connected layers\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","\n","        return x\n","print(\"MODEL LOADED, YOU MAY PROCEED\")"],"metadata":{"id":"D6O96ijaYJPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####################################################\n","# THIS IS THE TRAINING CODE; YOU CAN SAFELY CHANGE: #\n","#                                                   #\n","# batch_size                                        #\n","# learning_rate                                     #\n","# num_epochs                                        #\n","#                                                   #\n","# IF YOU MADE CHANGES TO THIS CODE, RERUN IT BEFORE #\n","# USING THE TESTING CODE                            #\n","#####################################################\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torchvision import transforms\n","from PIL import Image\n","import json\n","import os\n","import torch.cuda as cuda\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","device = torch.device('cuda')\n","\n","# Define dataset\n","class CustomDataset(data.Dataset):\n","    def __init__(self, image_folder, json_file, transform=None):\n","        with open(json_file) as f:\n","            self.data_info = json.load(f)\n","        self.image_keys = list(self.data_info.keys())\n","        self.image_folder = image_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data_info)\n","\n","    def __getitem__(self, idx):\n","        # Access the data using the keys\n","        image_key = self.image_keys[idx]\n","        img_name = os.path.join(self.image_folder, self.data_info[image_key][\"file_name\"])\n","        image = Image.open(img_name).convert('RGB')\n","        num_dots = self.data_info[image_key][\"num_dots\"]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, num_dots\n","\n","\n","\n","# Configuration\n","image_folder = \"/content/Math-4997-Summer-23/eggCounter/Fake eggs\"\n","json_file = \"/content/Math-4997-Summer-23/eggCounter/labels.json\"\n","\n","\n","\n","####################################\n","# Feel free to change these values #\n","batch_size = 32\n","learning_rate = 0.008\n","num_epochs = 10\n","####################################\n","\n","\n","\n","# Transformations\n","transform = transforms.Compose([\n","    transforms.RandomRotation(15),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ToTensor()\n","])\n","\n","# Load Dataset\n","dataset = CustomDataset(image_folder=image_folder, json_file=json_file, transform=transform)\n","dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Initialize model, loss and optimizer\n","model = CountingModel()\n","model.to(device)\n","criterion = nn.L1Loss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for images, num_dots in dataloader:\n","        images, num_dots = images.to(device), num_dots.to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, num_dots.float().unsqueeze(1))\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n","\n","# Save the model\n","model_state_dict = model.state_dict()\n","\n","# Define the model name\n","model_name = 'counting_model.ckpt'\n","\n","# Provide the file path to save the model state dictionary\n","file_path = f'/content/Math-4997-Summer-23/eggCounter/{model_name}'\n","torch.save(model_state_dict, file_path)\n","\n","print(\"\\nMODEL SAVED, YOU CAN PROCEED TO TEST\")"],"metadata":{"id":"Xj88BHhhYJi6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########################################################\n","# THIS IS TO TEST THE MODEL; IT HAS 4 IMAGES AS INPUTS #\n","#                                                      #\n","# 27-real AND 84-real ARE OUR REAL PICTURES OF EGGS    #\n","#                                                      #\n","# 120-dots AND 27-dots ARE SIMULATED IMAGES OF EGGS    #\n","# THAT WERE USED IN THE TRAINING MODEL                 #\n","#                                                      #\n","# THERE IS NOTHING TO BE CHANGED HERE                  #\n","########################################################\n","\n","\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","\n","# Load the trained model\n","model = CountingModel()\n","model.load_state_dict(torch.load(\"/content/Math-4997-Summer-23/eggCounter/counting_model.ckpt\"))\n","model.eval()\n","\n","# Define the image transformation\n","transform = transforms.Compose([\n","    transforms.Resize((360, 360)),\n","    transforms.ToTensor()\n","])\n","\n","# List of available image paths\n","image_paths = [\n","    \"/content/Math-4997-Summer-23/eggCounter/27-real.jpg\",\n","    \"/content/Math-4997-Summer-23/eggCounter/84-real.jpg\",\n","    \"/content/Math-4997-Summer-23/eggCounter/120-dots.png\",\n","    \"/content/Math-4997-Summer-23/eggCounter/27-dots.png\"\n","]\n","\n","# Iterate over the image paths\n","for image_path in image_paths:\n","    # Extract the image name from the file path\n","    image_name = os.path.basename(image_path)\n","\n","    # Load and transform the test image\n","    test_image = Image.open(image_path).convert('RGB')\n","    test_image = transform(test_image).unsqueeze(0)  # Add batch dimension\n","\n","    # Predict the number of dots\n","    with torch.no_grad():\n","        output = model(test_image)\n","\n","    predicted_count = int(torch.round(output.squeeze()))\n","\n","    print(\"Image:\\t\", image_name)\n","    print(\"Predicted Dot Count:\", predicted_count)\n","    print(\"-------------------\\n\")\n","\n","print(\"\\nIF YOU GET THE SAME NUMBER FOR PREDICTED DOT COUNT\")\n","print(\"PLEASE RERUN THE TRAINING CODE TO MAKE A NEW MODEL\")"],"metadata":{"id":"vQIt8yd1YJu7"},"execution_count":null,"outputs":[]}]}